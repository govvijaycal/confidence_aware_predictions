{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint Evaluation\n",
    "* The purpose of this notebook is to check prediction performance as a function of training epochs (checkpoints).\n",
    "* Includes train/val prediction errors and visualization of the latter image features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjustable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'log/nuscenes_multipath_lstm' # location of the weights relative to the repo.\n",
    "model_type     = 'multipath'                   # multipath or regression\n",
    "dataset_type  = 'nuscenes'                     # nuscenes or l5kit\n",
    "\n",
    "run_prediction_evaluation = True # visualize performance vs. training epoch\n",
    "run_layer_visualization   = True # visualize intermediate CNN activations vs. training epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "ROOTDIR = os.getcwd().split('scripts')[0]\n",
    "sys.path.append(os.path.join(ROOTDIR, 'scripts'))\n",
    "\n",
    "from models.regression import Regression\n",
    "from models.multipath import MultiPath\n",
    "from datasets.splits import NUSCENES_TRAIN, NUSCENES_VAL, L5KIT_TRAIN, L5KIT_VAL\n",
    "from datasets.tfrecord_utils import _parse_function\n",
    "from evaluation.gmm_prediction import GMMPrediction\n",
    "from evaluation.pandas_df_utils import eval_prediction_dict, average_selected_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = glob.glob(os.path.join(ROOTDIR, checkpoint_dir, '*.h5') )\n",
    "checkpoints.sort()\n",
    "if len(checkpoints) == 0:\n",
    "    raise ValueError(\"No records found!\")\n",
    "else:\n",
    "    print(\"{} records found.\".format(len(checkpoints)))\n",
    "\n",
    "if dataset_type == 'nuscenes':\n",
    "    n_t, n_h_t = 12, 2\n",
    "    anchors = np.load(os.path.join(ROOTDIR, 'data/nuscenes_clusters_16.npy'))\n",
    "    weights = np.load(os.path.join(ROOTDIR, 'data/nuscenes_clusters_16_weights.npy'))\n",
    "    train_records, val_records = NUSCENES_TRAIN, NUSCENES_VAL\n",
    "elif dataset_type == 'l5kit':\n",
    "    n_t, n_h_t = 25, 5\n",
    "    anchors = np.load(os.path.join(ROOTDIR, 'data/l5kit_clusters_16.npy'))\n",
    "    weights = np.load(os.path.join(ROOTDIR, 'data/l5kit_clusters_16_weights.npy'))\n",
    "    train_records, val_records = L5KIT_TRAIN, L5KIT_VAL\n",
    "else:\n",
    "    raise ValueError(\"{} not implemented\".format(dataset_type))\n",
    "        \n",
    "if model_type == 'multipath':\n",
    "    model = MultiPath(num_timesteps=n_t, num_hist_timesteps=n_h_t, anchors=anchors, weights=weights)\n",
    "elif model_type == 'regression':\n",
    "    model = Regression(num_timesteps=n_t, num_hist_timesteps=n_h_t)\n",
    "else:\n",
    "    raise ValueError(\"{} not implemented\".format(dataset_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if run_prediction_evaluation: \n",
    "    metric_key_prefixes = [\"traj_LL\", \"class_top\", \"min_ade\", \"min_fde\", \"minmax_dist\"]\n",
    "    ks_eval = [1,3,5]\n",
    "    keys_to_average = [f\"{x}_{y}\" for x in metric_key_prefixes for y in ks_eval]\n",
    "    \n",
    "    checkpoint_train_dict = defaultdict(lambda: [])\n",
    "    checkpoint_val_dict   = defaultdict(lambda: [])\n",
    "    \n",
    "    # Aggregate prediction metrics by checkpoint and by dataset split.\n",
    "    for checkpoint in checkpoints:\n",
    "        model.load_weights(checkpoint)\n",
    "        model_name = model.model.name + '_' + checkpoint.split('/')[-1].split('_')[0] # bit hacky, may need fixing\n",
    "        \n",
    "        for split in ['train', 'val']:\n",
    "            predictions_dict = model.predict( eval(f\"{split}_records\") )\n",
    "            metrics_df       = eval_prediction_dict(predictions_dict, anchors, model_name, ks_eval=ks_eval)\n",
    "            avg_df           = average_selected_keys(metrics_df, keys_to_average)\n",
    "            \n",
    "            checkpoint_df = eval(f\"checkpoint_{split}_dict\")\n",
    "            for key in avg_df.keys():\n",
    "                checkpoint_df[key].append(avg_df[key])\n",
    "            checkpoint_df['model'].append(model_name)\n",
    "    \n",
    "    # Plot Results Across Checkpoints.  Hard-coding the keys for now, future can make this automated.\n",
    "    epochs = [int(name.split('_')[-1]) for name in checkpoint_train_dict['model']]    \n",
    "    min_epoch, max_epoch = np.amin(epochs), np.amax(epochs)\n",
    "    epoch_delta = 10\n",
    "    epoch_ticks = np.arange(min_epoch, max_epoch + epoch_delta, epoch_delta).astype(np.int)\n",
    "        \n",
    "    for plot_ind, key_prefix in enumerate(metric_key_prefixes):\n",
    "        fig, ((ax1), (ax2)) = plt.subplots(1, 2, sharex=True, sharey=True)    \n",
    "        for k in ks_eval:    \n",
    "            ax1.plot(epochs, checkpoint_train_dict['%s_%d' % (key_prefix, k)], label='%d' % k)\n",
    "            ax2.plot(epochs, checkpoint_val_dict['%s_%d' % (key_prefix, k)], label='%d' % k)\n",
    "        ax1.set_xticks(epoch_ticks)\n",
    "        ax2.set_xticks(epoch_ticks)\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax2.set_xlabel('Epoch')   \n",
    "        ax1.set_ylabel(key_prefix)\n",
    "        ax1.grid()                \n",
    "        ax2.grid()\n",
    "        ax2.legend()    \n",
    "        fig.tight_layout()\n",
    "        \n",
    "        if plot_ind == 0:\n",
    "            plt.suptitle(\"Train / Val\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#[print(layer.name) for layer in model.model.layers] # To locate which layer to visualize.\n",
    "\n",
    "if run_layer_visualization:\n",
    "\n",
    "    target_layer = 'batch_normalization'\n",
    "\n",
    "    entry_to_viz = 15 # which dataset example to view\n",
    "    dataset = tf.data.TFRecordDataset(val_records)\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    dataset = dataset.batch(1)\n",
    "\n",
    "    img_orig, img_preprocessed = None, None\n",
    "    for ind_entry, entry in enumerate(dataset):\n",
    "        if ind_entry == entry_to_viz:\n",
    "            img_orig = entry['image']\n",
    "            img_preprocessed, _, _ = model.preprocess_entry(entry)\n",
    "\n",
    "    def plot_top_activations(activations, k=8):    \n",
    "        summed_activations = tf.reduce_sum(tf.abs(activations), axis=[0, 1, 2])\n",
    "        top_k = tf.math.top_k(summed_activations, k=k).indices.numpy()\n",
    "\n",
    "        for i, act_ind in enumerate(top_k):\n",
    "            plt.subplot(2, np.ceil(k/2), i+1)\n",
    "            plt.imshow(activations[0, :, :, act_ind], cmap='plasma')        \n",
    "\n",
    "    # See how the layer evolves over time with more training.\n",
    "    img_orig_ds = cv2.resize(img_orig[0].numpy(), (32,32), interpolation=cv2.INTER_AREA)\n",
    "    for checkpoint in checkpoints:\n",
    "        model.load_weights(checkpoint)\n",
    "        viz_model = tf.keras.Model(model.model.get_layer(name='image_input').output, \n",
    "                                   model.model.get_layer(name=target_layer).output)    \n",
    "        out = viz_model.predict_on_batch(img_preprocessed)\n",
    "        plt.figure()\n",
    "        plt.imshow(img_orig_ds)\n",
    "\n",
    "        plt.figure()\n",
    "        plot_top_activations(out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
