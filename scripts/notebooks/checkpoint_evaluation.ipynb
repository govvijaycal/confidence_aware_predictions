{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint Evaluation\n",
    "* The purpose of this notebook is to check prediction performance as a function of training epochs (checkpoints).\n",
    "* Includes train/val prediction errors and visualization of the latter image features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjustable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'log/l5kit_multipath_lstm'\n",
    "model_type     = 'multipath'\n",
    "dataset_type  = 'l5kit'\n",
    "\n",
    "run_prediction_evaluation = True\n",
    "run_layer_visualization   = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "ROOTDIR = os.getcwd().split('scripts')[0]\n",
    "sys.path.append(os.path.join(ROOTDIR, 'scripts'))\n",
    "\n",
    "from models.regression import Regression\n",
    "from models.multipath import MultiPath\n",
    "from datasets.splits import NUSCENES_TRAIN, NUSCENES_VAL, L5KIT_TRAIN, L5KIT_VAL\n",
    "from datasets.tfrecord_utils import _parse_function\n",
    "from evaluation.gmm_prediction import GMMPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = glob.glob(os.path.join(ROOTDIR, checkpoint_dir, '*.h5') )\n",
    "checkpoints.sort()\n",
    "if len(checkpoints) == 0:\n",
    "    raise ValueError(\"No records found!\")\n",
    "else:\n",
    "    print(\"{} records found.\".format(len(checkpoints)))\n",
    "\n",
    "if dataset_type == 'nuscenes':\n",
    "    n_t, n_h_t = 12, 2\n",
    "    anchors = np.load(os.path.join(ROOTDIR, 'data/nuscenes_clusters_16.npy'))\n",
    "    weights = np.load(os.path.join(ROOTDIR, 'data/nuscenes_clusters_16_weights.npy'))\n",
    "    train_records, val_records = NUSCENES_TRAIN, NUSCENES_VAL\n",
    "elif dataset_type == 'l5kit':\n",
    "    n_t, n_h_t = 25, 5\n",
    "    anchors = np.load(os.path.join(ROOTDIR, 'data/l5kit_clusters_16.npy'))\n",
    "    weights = np.load(os.path.join(ROOTDIR, 'data/l5kit_clusters_16_weights.npy'))\n",
    "    train_records, val_records = L5KIT_TRAIN, L5KIT_VAL\n",
    "else:\n",
    "    raise ValueError(\"{} not implemented\".format(dataset_type))\n",
    "        \n",
    "if model_type == 'multipath':\n",
    "    model = MultiPath(num_timesteps=n_t, num_hist_timesteps=n_h_t, anchors=anchors, weights=weights)\n",
    "elif model_type == 'regression':\n",
    "    model = Regression(num_timesteps=n_t, num_hist_timesteps=n_h_t)\n",
    "else:\n",
    "    raise ValueError(\"{} not implemented\".format(dataset_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def eval_prediction_dict(predict_dict, model_name):\n",
    "    data_list = []\n",
    "    ks_eval = [1, 3, 5]\n",
    "\n",
    "    columns   = [\"sample\", \"instance\", \"model\"]\n",
    "    columns.extend([f\"traj_LL_{k}\" for k in ks_eval])\n",
    "    columns.extend([f\"class_top_{k}\" for k in ks_eval])\n",
    "    columns.extend([f\"min_ade_{k}\" for k in ks_eval])\n",
    "    columns.extend([f\"min_fde_{k}\" for k in ks_eval])\n",
    "    columns.extend([f\"minmax_dist_{k}\" for k in ks_eval])\n",
    "\n",
    "    for key in tqdm(predict_dict.keys()):\n",
    "        future_traj_gt = predict_dict[key]['future_traj']\n",
    "        future_xy_gt = future_traj_gt[:, 1:3]\n",
    "        gmm_pred       = predict_dict[key]['gmm_pred']\n",
    "\n",
    "        n_modes     = len(gmm_pred.keys())\n",
    "        n_timesteps = future_traj_gt.shape[0]\n",
    "        mode_probabilities = np.array( [gmm_pred[mode]['mode_probability'] for mode in range(n_modes)] )\n",
    "        mus                = np.array( [gmm_pred[mode]['mus'] for mode in range(n_modes)] )\n",
    "        sigmas             = np.array( [gmm_pred[mode]['sigmas'] for mode in range(n_modes)] )\n",
    "\n",
    "        gmm_pred     = GMMPrediction(n_modes, n_timesteps, mode_probabilities, mus, sigmas)\n",
    "\n",
    "        sample_token   = '_'.join( key.split('_')[:-2] )\n",
    "        instance_token = '_'.join( key.split('_')[-2:] )\n",
    "\n",
    "        data_list_entry = [sample_token, instance_token, model_name]\n",
    "        if n_modes == 1:\n",
    "            num_ks = len(ks_eval)\n",
    "            data_list_entry.extend([gmm_pred.compute_trajectory_log_likelihood(future_xy_gt)]*num_ks)\n",
    "            data_list_entry.extend([1]*num_ks) # unimodal\n",
    "            data_list_entry.extend([gmm_pred.compute_min_ADE(future_xy_gt)]*num_ks)\n",
    "            data_list_entry.extend([gmm_pred.compute_min_FDE(future_xy_gt)]*num_ks)\n",
    "            data_list_entry.extend([gmm_pred.compute_minmax_d(future_xy_gt)]*num_ks)\n",
    "        else:\n",
    "            gmm_pred_ks  = [gmm_pred.get_top_k_GMM(k) for k in ks_eval]\n",
    "\n",
    "            data_list_entry.extend([gmm_pred_k.compute_trajectory_log_likelihood(future_xy_gt) \\\n",
    "                                    for gmm_pred_k in gmm_pred_ks])\n",
    "            data_list_entry.extend(gmm_pred.get_class_top_k_scores(future_xy_gt, anchors, ks_eval))\n",
    "            data_list_entry.extend([gmm_pred_k.compute_min_ADE(future_xy_gt) \\\n",
    "                                    for gmm_pred_k in gmm_pred_ks])\n",
    "            data_list_entry.extend([gmm_pred_k.compute_min_FDE(future_xy_gt) \\\n",
    "                                    for gmm_pred_k in gmm_pred_ks])\n",
    "            data_list_entry.extend([gmm_pred_k.compute_minmax_d(future_xy_gt) \\\n",
    "                                    for gmm_pred_k in gmm_pred_ks])\n",
    "\n",
    "        data_list.append(data_list_entry)\n",
    "    metrics_df = pd.DataFrame(data_list, columns=columns)\n",
    "    return metrics_df\n",
    "\n",
    "def average_selected_metrics(df, relevant_keys):\n",
    "    avg_dict = {}\n",
    "    for key in relevant_keys:\n",
    "        avg_dict[key] = np.mean(df[key])\n",
    "    return avg_dict\n",
    "\n",
    "def select_relevant_keys(df):\n",
    "    relevant_keys = []\n",
    "    \n",
    "    for key in df.columns:\n",
    "        if 'class' in key:        # mode classification\n",
    "            pass\n",
    "        elif 'ade' in key:        # min ADE\n",
    "            pass\n",
    "        elif 'fde' in key:        # min FDE\n",
    "            pass\n",
    "        elif 'traj_LL' in key:    # log likelihood\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "        relevant_keys.append(key)\n",
    "        \n",
    "    return relevant_keys\n",
    "    \n",
    "if run_prediction_evaluation:    \n",
    "    checkpoint_train_dict = {'model': []}\n",
    "    checkpoint_val_dict   = {'model': []}\n",
    "    \n",
    "    for checkpoint in checkpoints:\n",
    "        model.load_weights(checkpoint)\n",
    "        model_name = model.model.name + '_' + checkpoint.split('/')[-1].split('_')[0] # bit hacky, may need fixing\n",
    "        \n",
    "        predictions_train_dict = model.predict(train_records)\n",
    "        train_df = eval_prediction_dict(predictions_train_dict, model_name)\n",
    "        avg_train_df = average_selected_metrics(train_df, select_relevant_keys(train_df))\n",
    "        for key in avg_train_df.keys():\n",
    "            if key in checkpoint_train_dict.keys():\n",
    "                checkpoint_train_dict[key].append(avg_train_df[key])\n",
    "            else:\n",
    "                checkpoint_train_dict[key] = [avg_train_df[key]]\n",
    "        checkpoint_train_dict['model'].append(model_name) \n",
    "        \n",
    "        predictions_val_dict = model.predict(val_records)\n",
    "        val_df = eval_prediction_dict(predictions_val_dict, model_name)\n",
    "        avg_val_df = average_selected_metrics(val_df, select_relevant_keys(val_df))\n",
    "        for key in avg_val_df.keys():\n",
    "            if key in checkpoint_val_dict.keys():\n",
    "                checkpoint_val_dict[key].append(avg_val_df[key])\n",
    "            else:\n",
    "                checkpoint_val_dict[key] = [avg_val_df[key]]\n",
    "        checkpoint_val_dict['model'].append(model_name) \n",
    "    \n",
    "    # Plot Results Across Checkpoints.  Hard-coding the keys for now, future can make this automated.\n",
    "    epochs = [int(name.split('_')[-1]) for name in checkpoint_train_dict['model']]    \n",
    "    min_epoch, max_epoch = np.amin(epochs), np.amax(epochs)\n",
    "    epoch_delta = 10\n",
    "    epoch_ticks = np.arange(min_epoch, max_epoch + epoch_delta, epoch_delta).astype(np.int)\n",
    "    print('Train\\tVal')\n",
    "    \n",
    "    key_prefixes = ['traj_LL', 'class_top', 'min_ade', 'min_fde']\n",
    "    for key_prefix in key_prefixes:\n",
    "        fig, ((ax1), (ax2)) = plt.subplots(1, 2, sharex=True, sharey=True)    \n",
    "        for k in [1,3,5]:    \n",
    "            ax1.plot(epochs, checkpoint_train_dict['%s_%d' % (key_prefix, k)], label='%d' % k)\n",
    "            ax2.plot(epochs, checkpoint_val_dict['%s_%d' % (key_prefix, k)], label='%d' % k)\n",
    "        ax1.set_xticks(epoch_ticks)\n",
    "        ax2.set_xticks(epoch_ticks)\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax2.set_xlabel('Epoch')   \n",
    "        ax1.set_ylabel(key_prefix)\n",
    "        ax1.grid()                \n",
    "        ax2.grid()\n",
    "        ax2.legend()    \n",
    "        fig.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#[print(layer.name) for layer in model.model.layers] # To locate which layer to visualize.\n",
    "\n",
    "if run_layer_visualization:\n",
    "\n",
    "    target_layer = 'batch_normalization'\n",
    "\n",
    "    entry_to_viz = 15 # which dataset example to view\n",
    "    dataset = tf.data.TFRecordDataset(val_records)\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    dataset = dataset.batch(1)\n",
    "\n",
    "    img_orig, img_preprocessed = None, None\n",
    "    for ind_entry, entry in enumerate(dataset):\n",
    "        if ind_entry == entry_to_viz:\n",
    "            img_orig = entry['image']\n",
    "            img_preprocessed, _, _ = model.preprocess_entry(entry)\n",
    "\n",
    "    def plot_top_activations(activations, k=8):    \n",
    "        summed_activations = tf.reduce_sum(tf.abs(activations), axis=[0, 1, 2])\n",
    "        top_k = tf.math.top_k(summed_activations, k=k).indices.numpy()\n",
    "\n",
    "        for i, act_ind in enumerate(top_k):\n",
    "            plt.subplot(2, np.ceil(k/2), i+1)\n",
    "            plt.imshow(activations[0, :, :, act_ind], cmap='plasma')        \n",
    "\n",
    "    # See how the layer evolves over time with more training.\n",
    "    img_orig_ds = cv2.resize(img_orig[0].numpy(), (32,32), interpolation=cv2.INTER_AREA)\n",
    "    for checkpoint in checkpoints:\n",
    "        model.load_weights(checkpoint)\n",
    "        viz_model = tf.keras.Model(model.model.get_layer(name='image_input').output, \n",
    "                                   model.model.get_layer(name=target_layer).output)    \n",
    "        out = viz_model.predict_on_batch(img_preprocessed)\n",
    "        plt.figure()\n",
    "        plt.imshow(img_orig_ds)\n",
    "\n",
    "        plt.figure()\n",
    "        plot_top_activations(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
